#Train, test and get feature importance for HistGradientBoostingRegressor
with cProfile.Profile() as pr:
  hreg = HistGradientBoostingRegressor(max_iter = 1000, loss = 'squared_error')
  hreg.fit(train_x ,train_y)
  print("time to fit:")
  stats = Stats(pr)
  stats.sort_stats('tottime').print_stats(5)

with cProfile.Profile() as pr:
    get_scores("hreg", hreg, val_x, val_y)
    print("time to run:")
    stats = Stats(pr)
    stats.sort_stats('tottime').print_stats(5)
  
get_feature_importance('hreg', hreg, val_x, val_y, df)

#Train, test, and get feature importance for RandomForest
with cProfile.Profile() as pr:
  rfreg = RandomForestRegressor(n_estimators = 100, min_samples_split = 3, min_samples_leaf = 3, random_state = 101)
  rfreg.fit(train_x, train_y)
  print("time to fit:")
  stats = Stats(pr)
  stats.sort_stats('tottime').print_stats(5)

with cProfile.Profile() as pr:
  get_scores("rfreg", rfreg, val_x, val_y)
  print("time to run:")
  stats = Stats(pr)
  stats.sort_stats('tottime').print_stats(5)

get_feature_importance('rfreg', rfreg, val_x, val_y, df)

#Train, test, and get coefficients for LinearRegression
with cProfile.Profile() as pr:
  linreg = LinearRegression()
  linreg.fit(train_x, train_y)
  print("time to fit:")
  stats = Stats(pr)
  stats.sort_stats('tottime').print_stats(5)

with cProfile.Profile() as pr:
  get_scores("linreg", linreg, val_x, val_y)
  print("time to run:")
  stats = Stats(pr)
  stats.sort_stats('tottime').print_stats(5)

print("Coefficients for linreg")
for i in range(len(linreg.coef_)):
  print(f'{df.columns[i + 1]}: {linreg.coef_[i]}')

#Train and test ensembled HistGradientBoostingRegressor
with cProfile.Profile() as pr:
  ensemble_hreg = build_fit_ensemble_hreg(train_sets_x, train_sets_y)
  print("time to fit:")
  stats = Stats(pr)
  stats.sort_stats('tottime').print_stats(5)

with cProfile.Profile() as pr:
  get_scores_ensembled("ens-hreg", ensemble_hreg, val_x, val_y)
  print("time to run:")
  stats = Stats(pr)
  stats.sort_stats('tottime').print_stats(5)